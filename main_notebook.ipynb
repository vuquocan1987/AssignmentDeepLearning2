{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 18:11:04.351814: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-01 18:11:04.351839: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-01 18:11:04.352426: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-01 18:11:04.428082: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# get tiny-imagenet from huggingface datasets\n",
    "# https://huggingface.co/datasets/viewer/?dataset=tiny_imagenet\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2, DenseNet121, DenseNet169,EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# import early stopping and model checkpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training densenet121_top_variant_1_on_imagenet\n",
      "Epoch 1/50\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 5.1525 - accuracy: 0.0150\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00550, saving model to best_weights_densenet121_top_variant_1_on_imagenet.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2813/2813 [==============================] - 194s 56ms/step - loss: 5.1525 - accuracy: 0.0150 - val_loss: 5.4862 - val_accuracy: 0.0055\n",
      "Epoch 2/50\n",
      " 718/2813 [======>.......................] - ETA: 1:53 - loss: 5.0387 - accuracy: 0.0215"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m history, \u001b[39meval\u001b[39m \u001b[39m=\u001b[39m train_model(model, model_name,train_gen, X_val, y_val, X_test, y_test, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m save_history(history, model_name)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m \u001b[39m# Save results immediately.\u001b[39;00m\n",
      "\u001b[1;32m/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m checkpoint_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbest_weights_\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(checkpoint_path, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_gen, \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs, \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(X_val,y_val),\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[early_stopping, checkpoint])\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m \u001b[39m# Load the best weights\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W1sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m model\u001b[39m.\u001b[39mload_weights(checkpoint_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "HISTORY_DIR = \"training_histories\"\n",
    "if not os.path.exists(HISTORY_DIR):\n",
    "    os.makedirs(HISTORY_DIR)\n",
    "def save_history(history, model_name):\n",
    "    with open(os.path.join(HISTORY_DIR, model_name + \".pkl\"), 'wb') as file:\n",
    "        pickle.dump(history.history, file)\n",
    "\n",
    "\n",
    "def get_top_layers(img_shape, num_classes):\n",
    "    \"\"\"\n",
    "    This function provides different top layers for fine-tuning.\n",
    "    \"\"\"\n",
    "    # Flattening and dense layers\n",
    "    top_flat_dense = [\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return [top_flat_dense]\n",
    "\n",
    "parameters = {\n",
    "    \"imagenet\": {\n",
    "        \"dataset_path\": \"Maysee/tiny-imagenet\",\n",
    "        \"split\": [\"train\", \"valid\"],\n",
    "        \"input_shape\": (64, 64, 3),\n",
    "        \"num_classes\": 200,\n",
    "        \"image_key\": \"image\",\n",
    "    },\n",
    "    \"cifar10\": {\n",
    "        \"dataset_path\": \"cifar10\",\n",
    "        \"split\": [\"train\", \"test\"],\n",
    "        \"input_shape\": (32, 32, 3),\n",
    "        \"num_classes\": 10,\n",
    "        \"image_key\": \"img\",\n",
    "    },\n",
    "    # \"beans\": {\n",
    "    #     \"dataset_path\": \"beans\",\n",
    "    #     \"split\": [\"train+validation\", \"test\"],\n",
    "    #     \"input_shape\": (500, 500, 3),\n",
    "    #     \"num_classes\": 3\n",
    "    # }\n",
    "}\n",
    "\n",
    "# Define the base models\n",
    "base_model_functions = [\n",
    "    lambda shape: EfficientNetB0(include_top=False, input_shape=shape, weights=None),  # Replacing Xception\n",
    "    lambda shape: ResNet50(include_top=False, input_shape=shape, weights=None),\n",
    "    lambda shape: MobileNetV2(include_top=False, input_shape=shape, weights=None),\n",
    "    lambda shape: DenseNet121(include_top=False, input_shape=shape, weights=None),\n",
    "    lambda shape: DenseNet169(include_top=False, input_shape=shape, weights=None),\n",
    "    lambda shape: VGG16(include_top=False, input_shape=shape, weights=None)\n",
    "]\n",
    "def get_data_set(Parameter, validation_split=0.1):\n",
    "    train_dataset, test_dataset = load_dataset(Parameter[\"dataset_path\"], split=Parameter[\"split\"])\n",
    "    \n",
    "    # Processing images\n",
    "    images = train_dataset[Parameter[\"image_key\"]]\n",
    "    images = [img.convert(\"RGB\") if len(img.split()) == 1 else img for img in images]\n",
    "    labels = train_dataset['label']\n",
    "    X = np.array([np.array(img) for img in images])\n",
    "    # Normalize\n",
    "    y = np.array(labels)\n",
    "    # one hot encode\n",
    "    y = utils.to_categorical(y, num_classes=Parameter[\"num_classes\"])\n",
    "\n",
    "    # Process test images\n",
    "    test_images = test_dataset[Parameter[\"image_key\"]]\n",
    "    test_images = [img.convert(\"RGB\") if len(img.split()) == 1 else img for img in test_images]\n",
    "    test_labels = test_dataset['label']\n",
    "    X_test = np.array([np.array(img) for img in test_images])\n",
    "    # Normalize\n",
    "    y_test = np.array(test_labels)\n",
    "    # one hot encode\n",
    "    y_test = to_categorical(y_test, num_classes=Parameter[\"num_classes\"])\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_split, random_state=42, stratify=y)\n",
    "    \n",
    "    # Image Data Generator for augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "    rotation_range=40,            # Random rotation in the range [0, 40)\n",
    "    width_shift_range=0.2,        # Fraction of total width for random horizontal shifts\n",
    "    height_shift_range=0.2,       # Fraction of total height for random vertical shifts\n",
    "    shear_range=0.2,              # Shear Intensity (shear angle in counter-clockwise direction in degrees)\n",
    "    zoom_range=0.2,               # Range for random zoom\n",
    "    horizontal_flip=True,         # Randomly flip inputs horizontally\n",
    "    vertical_flip=True,           # Randomly flip inputs vertically\n",
    "    brightness_range=(0.8, 1.2),  # Range for picking a brightness shift value\n",
    "    fill_mode='nearest',          # Points outside the boundaries are filled according to the given mode\n",
    "    rescale=1./255                # Rescale factor (original_value * rescale)\n",
    ")\n",
    "    \n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    train_gen = datagen.flow(X_train, y_train, batch_size=32)    \n",
    "    return train_gen, X_val, y_val, X_test, y_test\n",
    "\n",
    "final_models = {}\n",
    "def train_model(model, model_name, train_gen, X_val,y_val, X_test, y_test, epochs=20, batch_size=32,):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Create EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
    "    \n",
    "    # Create ModelCheckpoint callback to save best model weights\n",
    "    checkpoint_path = f'best_weights_{model_name}.h5'\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "    \n",
    "    history = model.fit(train_gen, \n",
    "                        epochs=epochs, \n",
    "                        validation_data=(X_val,y_val),\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping, checkpoint])\n",
    "    \n",
    "    # Load the best weights\n",
    "    model.load_weights(checkpoint_path)\n",
    "    \n",
    "    eval = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    return history, eval\n",
    "\n",
    "\n",
    "# Initialize CSV file with headers\n",
    "# with open(\"model_training_results.csv\", \"w\") as file:\n",
    "    # file.write(\"dataset,base_model,top_layers_variant,model_name,train_accuracy,train_loss, test_accuracy\\n\")\n",
    "\n",
    "# add a counter skip first models\n",
    "\n",
    "skip = 0\n",
    "counter = 0\n",
    "for dataset, data_params in parameters.items():\n",
    "    # Load data for each dataset\n",
    "    train_gen, X_val, y_val, X_test, y_test = get_data_set(data_params)\n",
    "    \n",
    "    img_shape = data_params[\"input_shape\"]\n",
    "    num_classes = data_params[\"num_classes\"]\n",
    "\n",
    "    for base_func in base_model_functions:\n",
    "        base = base_func(img_shape)\n",
    "        top_layers_variants = get_top_layers(img_shape, num_classes)\n",
    "        \n",
    "        for idx, top_layers in enumerate(top_layers_variants):\n",
    "            counter += 1\n",
    "            if counter <= skip:\n",
    "                continue\n",
    "            \n",
    "            top_layers_name = f\"v2top_variant_{idx+1}\"\n",
    "            model_name = f\"{base.name}_{top_layers_name}_on_{dataset}\"\n",
    "            model = models.Sequential([base] + top_layers)\n",
    "            # print start training\n",
    "            print(f\"Training {model_name}\")\n",
    "            # Train the model\n",
    "            history, eval = train_model(model, model_name,train_gen, X_val, y_val, X_test, y_test, epochs=50)\n",
    "            save_history(history, model_name)\n",
    "            # Save results immediately.\n",
    "            with open(\"model_training_results.csv\", \"a\") as file:\n",
    "                file.write(f\"{dataset},{base.name},{top_layers_name},{model_name},{history.history['accuracy'][-1]},{history.history['loss'][-1]},{eval[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, X_val, y_val, X_test, y_test = get_data_set(parameters[\"cifar10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 34s 20ms/step - loss: 1.9981 - accuracy: 0.2007 - val_loss: 2.0425 - val_accuracy: 0.1875\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.6962 - accuracy: 0.3086 - val_loss: 1.8273 - val_accuracy: 0.3176\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.4705 - accuracy: 0.4161 - val_loss: 455226.7188 - val_accuracy: 0.2194\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.3446 - accuracy: 0.4867 - val_loss: 1.2088 - val_accuracy: 0.5559\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.1610 - accuracy: 0.5773 - val_loss: 1992930.5000 - val_accuracy: 0.5460\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.0237 - accuracy: 0.6400 - val_loss: 1.0984 - val_accuracy: 0.6199\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8809 - accuracy: 0.6941 - val_loss: 1033800.5000 - val_accuracy: 0.6836\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7708 - accuracy: 0.7361 - val_loss: 0.8514 - val_accuracy: 0.7120\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.6659 - accuracy: 0.7749 - val_loss: 0.7851 - val_accuracy: 0.7455\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.5715 - accuracy: 0.8098 - val_loss: 0.7839 - val_accuracy: 0.7564\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.4873 - accuracy: 0.8390 - val_loss: 2401175.7500 - val_accuracy: 0.7684\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.4182 - accuracy: 0.8635 - val_loss: 0.7504 - val_accuracy: 0.7715\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.3557 - accuracy: 0.8838 - val_loss: 8104014.5000 - val_accuracy: 0.7801\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.3041 - accuracy: 0.9018 - val_loss: 0.8232 - val_accuracy: 0.7842\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.2619 - accuracy: 0.9162 - val_loss: 0.8720 - val_accuracy: 0.7855\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.2274 - accuracy: 0.9280 - val_loss: 0.8024 - val_accuracy: 0.7932\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.1966 - accuracy: 0.9381 - val_loss: 0.7917 - val_accuracy: 0.7971\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.1678 - accuracy: 0.9481 - val_loss: 130.7779 - val_accuracy: 0.7946\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1595 - accuracy: 0.9513 - val_loss: 30.4203 - val_accuracy: 0.7893\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1413 - accuracy: 0.9576 - val_loss: 0.8712 - val_accuracy: 0.8031\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1294 - accuracy: 0.9608 - val_loss: 0.8755 - val_accuracy: 0.7979\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1151 - accuracy: 0.9653 - val_loss: 23.3274 - val_accuracy: 0.7911\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1079 - accuracy: 0.9672 - val_loss: 0.9014 - val_accuracy: 0.8044\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1063 - accuracy: 0.9674 - val_loss: 0.9804 - val_accuracy: 0.8006\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0891 - accuracy: 0.9737 - val_loss: 1.1891 - val_accuracy: 0.7877\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0868 - accuracy: 0.9747 - val_loss: 1.1711 - val_accuracy: 0.7902\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0859 - accuracy: 0.9742 - val_loss: 1.1120 - val_accuracy: 0.7938\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0776 - accuracy: 0.9775 - val_loss: 1.2159 - val_accuracy: 0.7875\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0680 - accuracy: 0.9803 - val_loss: 1.0575 - val_accuracy: 0.8020\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0774 - accuracy: 0.9774 - val_loss: 1.0921 - val_accuracy: 0.8030\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0721 - accuracy: 0.9785 - val_loss: 1.0539 - val_accuracy: 0.8060\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0617 - accuracy: 0.9824 - val_loss: 1.1336 - val_accuracy: 0.7926\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0652 - accuracy: 0.9811 - val_loss: 1.1950 - val_accuracy: 0.7980\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0654 - accuracy: 0.9812 - val_loss: 0.9633 - val_accuracy: 0.8061\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0592 - accuracy: 0.9827 - val_loss: 1.1459 - val_accuracy: 0.7923\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0551 - accuracy: 0.9845 - val_loss: 1.1167 - val_accuracy: 0.7982\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0554 - accuracy: 0.9842 - val_loss: 1.0709 - val_accuracy: 0.8084\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0509 - accuracy: 0.9856 - val_loss: 1.0883 - val_accuracy: 0.8027\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0538 - accuracy: 0.9842 - val_loss: 1.0486 - val_accuracy: 0.8099\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0488 - accuracy: 0.9861 - val_loss: 1.0776 - val_accuracy: 0.8009\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0458 - accuracy: 0.9873 - val_loss: 1.0361 - val_accuracy: 0.8120\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 1.0912 - val_accuracy: 0.8059\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0455 - accuracy: 0.9867 - val_loss: 1.2407 - val_accuracy: 0.7944\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 1.1423 - val_accuracy: 0.8031\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0447 - accuracy: 0.9878 - val_loss: 2.3925 - val_accuracy: 0.8100\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0440 - accuracy: 0.9875 - val_loss: 1.0592 - val_accuracy: 0.7924\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0387 - accuracy: 0.9891 - val_loss: 1.1605 - val_accuracy: 0.8033\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 1.1160 - val_accuracy: 0.8111\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0366 - accuracy: 0.9897 - val_loss: 1.1497 - val_accuracy: 0.8064\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 1.4886 - val_accuracy: 0.7880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f11459ae9a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define VGG16 to train on CIFAR\n",
    "\n",
    "# load cifar on tensorflow\n",
    "\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "model = VGG16(include_top=False, input_shape=(32, 32, 3), weights=None)\n",
    "top_layer = Sequential([\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model = Sequential([model, top_layer])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 03:19:54.616203: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.57GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-29 03:19:54.616236: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.57GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-29 03:19:57.506256: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-29 03:19:57.506291: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 2.2755 - accuracy: 0.2987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 03:20:46.390011: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.57GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-29 03:20:46.390044: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.57GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 67s 30ms/step - loss: 2.2755 - accuracy: 0.2987 - val_loss: 4.7969 - val_accuracy: 0.2068\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.1729 - accuracy: 0.3154 - val_loss: 3.3727 - val_accuracy: 0.2232\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 2.0710 - accuracy: 0.3421 - val_loss: 3.0355 - val_accuracy: 0.2944\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.8615 - accuracy: 0.3835 - val_loss: 2.6305 - val_accuracy: 0.4379\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.7195 - accuracy: 0.4394 - val_loss: 1.7308 - val_accuracy: 0.4881\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.7233 - accuracy: 0.4416 - val_loss: 1.9355 - val_accuracy: 0.3019\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.8186 - accuracy: 0.3890 - val_loss: 5.8125 - val_accuracy: 0.3731\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.6317 - accuracy: 0.4597 - val_loss: 1.6369 - val_accuracy: 0.4231\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.5734 - accuracy: 0.4592 - val_loss: 2.9699 - val_accuracy: 0.4241\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.3834 - accuracy: 0.5213 - val_loss: 1.3582 - val_accuracy: 0.5310\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.3850 - accuracy: 0.5256 - val_loss: 1.3689 - val_accuracy: 0.5265\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.1962 - accuracy: 0.5811 - val_loss: 1.1384 - val_accuracy: 0.5974\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.1286 - accuracy: 0.6099 - val_loss: 1.1353 - val_accuracy: 0.6248\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.9981 - accuracy: 0.6510 - val_loss: 1.1052 - val_accuracy: 0.6160\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.0244 - accuracy: 0.6523 - val_loss: 2.5304 - val_accuracy: 0.5249\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.8482 - accuracy: 0.7069 - val_loss: 0.8894 - val_accuracy: 0.6944\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7638 - accuracy: 0.7340 - val_loss: 1.1143 - val_accuracy: 0.6224\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7182 - accuracy: 0.7502 - val_loss: 0.8735 - val_accuracy: 0.6954\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6270 - accuracy: 0.7821 - val_loss: 0.8613 - val_accuracy: 0.7144\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5920 - accuracy: 0.7931 - val_loss: 0.9355 - val_accuracy: 0.6936\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5176 - accuracy: 0.8224 - val_loss: 0.8369 - val_accuracy: 0.7287\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4590 - accuracy: 0.8403 - val_loss: 0.9601 - val_accuracy: 0.7176\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.3930 - accuracy: 0.8629 - val_loss: 0.9712 - val_accuracy: 0.7081\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.3562 - accuracy: 0.8764 - val_loss: 1.3401 - val_accuracy: 0.6314\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.3267 - accuracy: 0.8851 - val_loss: 1.5003 - val_accuracy: 0.7136\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.2522 - accuracy: 0.9120 - val_loss: 1.1321 - val_accuracy: 0.6987\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.2281 - accuracy: 0.9221 - val_loss: 0.9877 - val_accuracy: 0.7423\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.1909 - accuracy: 0.9341 - val_loss: 1.0588 - val_accuracy: 0.7385\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.1713 - accuracy: 0.9411 - val_loss: 1.1386 - val_accuracy: 0.7273\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.1565 - accuracy: 0.9459 - val_loss: 1.2887 - val_accuracy: 0.7070\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.1294 - accuracy: 0.9552 - val_loss: 1.4010 - val_accuracy: 0.7142\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1590 - accuracy: 0.9470 - val_loss: 1.2962 - val_accuracy: 0.7222\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.1644 - accuracy: 0.9452 - val_loss: 1.0336 - val_accuracy: 0.7357\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.1143 - accuracy: 0.9608 - val_loss: 1.2335 - val_accuracy: 0.7382\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.1118 - accuracy: 0.9617 - val_loss: 1.1572 - val_accuracy: 0.7505\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.0943 - accuracy: 0.9671 - val_loss: 1.5383 - val_accuracy: 0.6976\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.0892 - accuracy: 0.9699 - val_loss: 1.4037 - val_accuracy: 0.7024\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.1069 - accuracy: 0.9634 - val_loss: 1.2716 - val_accuracy: 0.7545\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.0735 - accuracy: 0.9754 - val_loss: 1.3552 - val_accuracy: 0.7436\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.0783 - accuracy: 0.9733 - val_loss: 1.5369 - val_accuracy: 0.7000\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.0822 - accuracy: 0.9726 - val_loss: 1.3086 - val_accuracy: 0.7287\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.0721 - accuracy: 0.9752 - val_loss: 1.3244 - val_accuracy: 0.7387\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.0759 - accuracy: 0.9751 - val_loss: 1.8907 - val_accuracy: 0.6931\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.0818 - accuracy: 0.9727 - val_loss: 1.2939 - val_accuracy: 0.7429\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.0649 - accuracy: 0.9786 - val_loss: 1.3010 - val_accuracy: 0.7405\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.0695 - accuracy: 0.9764 - val_loss: 1.4593 - val_accuracy: 0.7205\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.0720 - accuracy: 0.9759 - val_loss: 1.1998 - val_accuracy: 0.7456\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.0764 - accuracy: 0.9755 - val_loss: 1.3851 - val_accuracy: 0.7525\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.0513 - accuracy: 0.9837 - val_loss: 1.5334 - val_accuracy: 0.7258\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.0665 - accuracy: 0.9782 - val_loss: 1.4965 - val_accuracy: 0.7359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1145e0f5b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define resnet50 for cifar\n",
    "\n",
    "model = ResNet50(include_top=False, input_shape=(32, 32, 3), weights=None)\n",
    "\n",
    "top_layer = Sequential([\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model = Sequential([model, top_layer])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1,d2 = load_dataset(\"Maysee/tiny-imagenet\", split=[\"train\", \"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = d1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# After training all models\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m trained_model_names \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbase\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_top_variant_\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_on_\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m base \u001b[39min\u001b[39;00m base_model_functions \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m plot_training_histories(trained_model_names)\n",
      "\u001b[1;32m/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# After training all models\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m trained_model_names \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbase\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_top_variant_\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_on_\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m base \u001b[39min\u001b[39;00m base_model_functions \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m plot_training_histories(trained_model_names)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_histories(model_names):\n",
    "    for model_name in model_names:\n",
    "        with open(os.path.join(HISTORY_DIR, model_name + \".pkl\"), 'rb') as file:\n",
    "            history = pickle.load(file)\n",
    "        \n",
    "        # Plotting training and validation accuracy\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title(f'Accuracy for {model_name}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plotting training and validation loss\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history['loss'], label='Training Loss')\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.title(f'Loss for {model_name}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# After training all models\n",
    "trained_model_names = [f\"{base.name}_top_variant_{idx+1}_on_{dataset}\" for base in base_model_functions for idx in range(3)]\n",
    "plot_training_histories(trained_model_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define resnet 18 to train on cifar10\n",
    "from keras.models import Model\n",
    "class ResnetBlock(Model):\n",
    "    def __init__(self, channels: int, down_sample=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.down_sample = down_sample\n",
    "        self.channels = channels\n",
    "        # Set stride to (2, 2) if downsampling is required\n",
    "        self.conv1_stride = (2, 2) if self.down_sample else (1, 1)\n",
    "        self.conv1 = layers.Conv2D(self.channels, (3, 3), padding='same', activation='relu', strides=self.conv1_stride)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(self.channels, (3, 3), padding='same', activation='relu')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        if self.down_sample:\n",
    "            self.downsample_conv = layers.Conv2D(self.channels, (1, 1), strides=(2, 2), padding='same', activation='relu')\n",
    "            self.downsample_bn = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        residual = inputs\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.down_sample:\n",
    "            residual = self.downsample_conv(inputs)\n",
    "            residual = self.downsample_bn(residual)\n",
    "        \n",
    "        x = layers.add([x, residual])\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "class ResNet18(Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(64, (7,7), strides=(2,2), padding='same', activation='relu')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.maxpool = layers.MaxPool2D((3,3), strides=(2,2), padding='same')\n",
    "        self.layer1 = ResnetBlock(64)\n",
    "        self.layer2 = ResnetBlock(128, down_sample=True)\n",
    "        self.layer3 = ResnetBlock(256, down_sample=True)\n",
    "        self.layer4 = ResnetBlock(512, down_sample=True)\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classes, activation='softmax')\n",
    "    def call(self,inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x) \n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "model = ResNet18(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m ResNet18(\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_gen, X_val, y_val, X_test, y_test \u001b[39m=\u001b[39m get_data_set(parameters[\u001b[39m\"\u001b[39;49m\u001b[39mcifar10\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_train \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_test \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X15sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_data_set\u001b[39m(Parameter, validation_split\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X15sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     train_dataset, test_dataset \u001b[39m=\u001b[39m load_dataset(Parameter[\u001b[39m\"\u001b[39;49m\u001b[39mdataset_path\u001b[39;49m\u001b[39m\"\u001b[39;49m], split\u001b[39m=\u001b[39;49mParameter[\u001b[39m\"\u001b[39;49m\u001b[39msplit\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X15sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39m# Processing images\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X15sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     images \u001b[39m=\u001b[39m train_dataset[Parameter[\u001b[39m\"\u001b[39m\u001b[39mimage_key\u001b[39m\u001b[39m\"\u001b[39m]]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/datasets/load.py:2129\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[1;32m   2125\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2126\u001b[0m )\n\u001b[1;32m   2128\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2129\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   2130\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   2131\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2132\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   2133\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   2134\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2135\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2136\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2137\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2138\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2139\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2140\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2141\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   2142\u001b[0m )\n\u001b[1;32m   2144\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2145\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/datasets/load.py:1815\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1813\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1814\u001b[0m     download_config\u001b[39m.\u001b[39mstorage_options\u001b[39m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1815\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1816\u001b[0m     path,\n\u001b[1;32m   1817\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1818\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1819\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1820\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1821\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1822\u001b[0m )\n\u001b[1;32m   1823\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1824\u001b[0m builder_kwargs \u001b[39m=\u001b[39m dataset_module\u001b[39m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/datasets/load.py:1481\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m   1480\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39min\u001b[39;00m [sibling\u001b[39m.\u001b[39mrfilename \u001b[39mfor\u001b[39;00m sibling \u001b[39min\u001b[39;00m dataset_info\u001b[39m.\u001b[39msiblings]:\n\u001b[0;32m-> 1481\u001b[0m     \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithScript(\n\u001b[1;32m   1482\u001b[0m         path,\n\u001b[1;32m   1483\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1484\u001b[0m         download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1485\u001b[0m         download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1486\u001b[0m         dynamic_modules_path\u001b[39m=\u001b[39;49mdynamic_modules_path,\n\u001b[1;32m   1487\u001b[0m     )\u001b[39m.\u001b[39mget_module()\n\u001b[1;32m   1488\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1489\u001b[0m     \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithoutScript(\n\u001b[1;32m   1490\u001b[0m         path,\n\u001b[1;32m   1491\u001b[0m         revision\u001b[39m=\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1495\u001b[0m         download_mode\u001b[39m=\u001b[39mdownload_mode,\n\u001b[1;32m   1496\u001b[0m     )\u001b[39m.\u001b[39mget_module()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/datasets/load.py:1159\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithScript.__init__\u001b[0;34m(self, name, revision, download_config, download_mode, dynamic_modules_path)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_mode \u001b[39m=\u001b[39m download_mode\n\u001b[1;32m   1158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_modules_path \u001b[39m=\u001b[39m dynamic_modules_path\n\u001b[0;32m-> 1159\u001b[0m increase_load_count(name, resource_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/datasets/load.py:232\u001b[0m, in \u001b[0;36mincrease_load_count\u001b[0;34m(name, resource_type)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mHF_DATASETS_OFFLINE \u001b[39mand\u001b[39;00m config\u001b[39m.\u001b[39mHF_UPDATE_DOWNLOAD_COUNTS:\n\u001b[1;32m    231\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m         head_hf_s3(name, filename\u001b[39m=\u001b[39;49mname \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.py\u001b[39;49m\u001b[39m\"\u001b[39;49m, dataset\u001b[39m=\u001b[39;49m(resource_type \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    233\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/datasets/utils/file_utils.py:96\u001b[0m, in \u001b[0;36mhead_hf_s3\u001b[0;34m(identifier, filename, use_cdn, dataset, max_retries)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhead_hf_s3\u001b[39m(\n\u001b[1;32m     94\u001b[0m     identifier: \u001b[39mstr\u001b[39m, filename: \u001b[39mstr\u001b[39m, use_cdn\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dataset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_retries\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     95\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[requests\u001b[39m.\u001b[39mResponse, \u001b[39mException\u001b[39;00m]:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m http_head(\n\u001b[1;32m     97\u001b[0m         hf_bucket_url(identifier\u001b[39m=\u001b[39;49midentifier, filename\u001b[39m=\u001b[39;49mfilename, use_cdn\u001b[39m=\u001b[39;49muse_cdn, dataset\u001b[39m=\u001b[39;49mdataset),\n\u001b[1;32m     98\u001b[0m         max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m     99\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/datasets/utils/file_utils.py:429\u001b[0m, in \u001b[0;36mhttp_head\u001b[0;34m(url, proxies, headers, cookies, allow_redirects, timeout, max_retries)\u001b[0m\n\u001b[1;32m    427\u001b[0m headers \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(headers) \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    428\u001b[0m headers[\u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m get_datasets_user_agent(user_agent\u001b[39m=\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 429\u001b[0m response \u001b[39m=\u001b[39m _request_with_retry(\n\u001b[1;32m    430\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHEAD\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    431\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    432\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    433\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    434\u001b[0m     cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[1;32m    435\u001b[0m     allow_redirects\u001b[39m=\u001b[39;49mallow_redirects,\n\u001b[1;32m    436\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    437\u001b[0m     max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m    438\u001b[0m )\n\u001b[1;32m    439\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/datasets/utils/file_utils.py:328\u001b[0m, in \u001b[0;36m_request_with_retry\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, **params)\u001b[0m\n\u001b[1;32m    326\u001b[0m tries \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    327\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod\u001b[39m.\u001b[39;49mupper(), url\u001b[39m=\u001b[39;49murl, timeout\u001b[39m=\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    329\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[39mexcept\u001b[39;00m (requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectTimeout, requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectionError) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/urllib3/connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    404\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    405\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/urllib3/connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[1;32m   1056\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1057\u001b[0m         (\n\u001b[1;32m   1058\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1064\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/urllib3/connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    411\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_certs\n\u001b[1;32m    412\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_cert_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(context, \u001b[39m\"\u001b[39m\u001b[39mload_default_certs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    416\u001b[0m ):\n\u001b[1;32m    417\u001b[0m     context\u001b[39m.\u001b[39mload_default_certs()\n\u001b[0;32m--> 419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[1;32m    420\u001b[0m     sock\u001b[39m=\u001b[39;49mconn,\n\u001b[1;32m    421\u001b[0m     keyfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[1;32m    422\u001b[0m     certfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[1;32m    423\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[1;32m    424\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[1;32m    425\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[1;32m    426\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[1;32m    427\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    428\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[1;32m    429\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[1;32m    430\u001b[0m )\n\u001b[1;32m    432\u001b[0m \u001b[39m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m# for the host.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    436\u001b[0m     default_ssl_context\n\u001b[1;32m    437\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock, \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    439\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock\u001b[39m.\u001b[39mversion() \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mTLSv1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTLSv1.1\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m    440\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/urllib3/util/ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    437\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    438\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn HTTPS request has been made, but the SNI (Server Name \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndication) extension to TLS is not available on this platform. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m         SNIMissingWarning,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m send_sni:\n\u001b[0;32m--> 449\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(\n\u001b[1;32m    450\u001b[0m         sock, context, tls_in_tls, server_hostname\u001b[39m=\u001b[39;49mserver_hostname\n\u001b[1;32m    451\u001b[0m     )\n\u001b[1;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/urllib3/util/ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[39mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m    492\u001b[0m \u001b[39mif\u001b[39;00m server_hostname:\n\u001b[0;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n\u001b[1;32m    494\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39mwrap_socket(sock)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/ssl.py:501\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    498\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    499\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[1;32m    502\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[1;32m    503\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[1;32m    504\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[1;32m    505\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[1;32m    506\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    507\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    508\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[1;32m    509\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/ssl.py:1074\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m   1072\u001b[0m             \u001b[39m# non-blocking\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1074\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1075\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1076\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/ssl.py:1343\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1341\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mand\u001b[39;00m block:\n\u001b[1;32m   1342\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1343\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1344\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(timeout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ResNet18(10)\n",
    "\n",
    "train_gen, X_val, y_val, X_test, y_test = get_data_set(parameters[\"cifar10\"])\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "aug = ImageDataGenerator(horizontal_flip=True, width_shift_range=0.05,\n",
    "                             height_shift_range=0.05)\n",
    "aug.fit(X_train)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "STEPS = len(X_train) // 256\n",
    "history = model.fit(aug.flow(X_train,Y_train,batch_size = 256), steps_per_epoch=STEPS, batch_size = 256, epochs=50, validation_data=(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 1.7293 - accuracy: 0.3662 - val_loss: 1.3383 - val_accuracy: 0.5160\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.3640 - accuracy: 0.5178 - val_loss: 1.1635 - val_accuracy: 0.5772\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2166 - accuracy: 0.5739 - val_loss: 1.0647 - val_accuracy: 0.6210\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1193 - accuracy: 0.6079 - val_loss: 1.0425 - val_accuracy: 0.6340\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0486 - accuracy: 0.6336 - val_loss: 0.9562 - val_accuracy: 0.6630\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9906 - accuracy: 0.6570 - val_loss: 0.9339 - val_accuracy: 0.6764\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9404 - accuracy: 0.6716 - val_loss: 0.9261 - val_accuracy: 0.6769\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9015 - accuracy: 0.6866 - val_loss: 0.9016 - val_accuracy: 0.6946\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8708 - accuracy: 0.6974 - val_loss: 0.8944 - val_accuracy: 0.6940\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8401 - accuracy: 0.7077 - val_loss: 0.8749 - val_accuracy: 0.7027\n",
      "313/313 - 0s - loss: 0.8749 - accuracy: 0.7027 - 360ms/epoch - 1ms/step\n",
      "\n",
      "Test accuracy: 0.7027000188827515\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),  # Dropout layer to prevent overfitting\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"\\nTest accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "X_train, y_train = train_images, train_labels\n",
    "X_test, y_test = test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model5\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# model5.fit_generator(train_generator,epochs=200,steps_per_epoch=training_steps,validation_data=test_generator,validation_steps=validation_steps,callbacks=[board])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#X21sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m history5\u001b[39m=\u001b[39mmodel5\u001b[39m.\u001b[39;49mfit(X_train,y_train,epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(X_test,y_test))\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileuxevbk1h.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/an/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, MaxPool2D\n",
    "model5 = Sequential()\n",
    "model5.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D((2, 2)))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D((2, 2)))\n",
    "model5.add(Dropout(0.3))\n",
    "model5.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPool2D((2, 2)))\n",
    "model5.add(Dropout(0.4))\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(10, activation='softmax'))\n",
    "# compile model\n",
    "# opt = SGD(lr=0.001, momentum=0.9)\n",
    "model5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model5.fit_generator(train_generator,epochs=200,steps_per_epoch=training_steps,validation_data=test_generator,validation_steps=validation_steps,callbacks=[board])\n",
    "history5=model5.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3357 - accuracy: 0.5384 - val_loss: 0.9109 - val_accuracy: 0.6780\n",
      "Epoch 2/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2657 - accuracy: 0.5616 - val_loss: 0.9625 - val_accuracy: 0.6674\n",
      "Epoch 3/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2355 - accuracy: 0.5727 - val_loss: 0.9310 - val_accuracy: 0.6764\n",
      "Epoch 4/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2176 - accuracy: 0.5826 - val_loss: 1.0849 - val_accuracy: 0.6350\n",
      "Epoch 5/50\n",
      "1407/1407 [==============================] - 18s 12ms/step - loss: 1.1959 - accuracy: 0.5887 - val_loss: 0.9218 - val_accuracy: 0.6878\n",
      "Epoch 6/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1777 - accuracy: 0.5970 - val_loss: 1.0360 - val_accuracy: 0.6444\n",
      "Epoch 7/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1627 - accuracy: 0.6036 - val_loss: 0.9382 - val_accuracy: 0.6806\n",
      "Epoch 8/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1543 - accuracy: 0.6051 - val_loss: 0.8955 - val_accuracy: 0.6922\n",
      "Epoch 9/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1399 - accuracy: 0.6113 - val_loss: 0.9508 - val_accuracy: 0.6690\n",
      "Epoch 10/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1290 - accuracy: 0.6128 - val_loss: 0.9070 - val_accuracy: 0.6814\n",
      "Epoch 11/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1247 - accuracy: 0.6160 - val_loss: 0.9209 - val_accuracy: 0.6872\n",
      "Epoch 12/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1081 - accuracy: 0.6194 - val_loss: 0.9520 - val_accuracy: 0.6652\n",
      "Epoch 13/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0986 - accuracy: 0.6282 - val_loss: 0.8632 - val_accuracy: 0.7016\n",
      "Epoch 14/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0827 - accuracy: 0.6345 - val_loss: 0.8392 - val_accuracy: 0.7068\n",
      "Epoch 15/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0733 - accuracy: 0.6350 - val_loss: 1.0486 - val_accuracy: 0.6604\n",
      "Epoch 16/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0648 - accuracy: 0.6359 - val_loss: 0.8404 - val_accuracy: 0.7132\n",
      "Epoch 17/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0606 - accuracy: 0.6403 - val_loss: 0.8912 - val_accuracy: 0.6910\n",
      "Epoch 18/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0533 - accuracy: 0.6440 - val_loss: 0.8360 - val_accuracy: 0.7122\n",
      "Epoch 19/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0424 - accuracy: 0.6483 - val_loss: 0.8431 - val_accuracy: 0.7066\n",
      "Epoch 20/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0376 - accuracy: 0.6485 - val_loss: 0.8099 - val_accuracy: 0.7198\n",
      "Epoch 21/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0391 - accuracy: 0.6484 - val_loss: 0.8215 - val_accuracy: 0.7240\n",
      "Epoch 22/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0291 - accuracy: 0.6521 - val_loss: 0.9249 - val_accuracy: 0.6918\n",
      "Epoch 23/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0273 - accuracy: 0.6544 - val_loss: 0.8515 - val_accuracy: 0.7096\n",
      "Epoch 24/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0166 - accuracy: 0.6580 - val_loss: 0.8611 - val_accuracy: 0.7126\n",
      "Epoch 25/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0100 - accuracy: 0.6569 - val_loss: 0.8895 - val_accuracy: 0.7050\n",
      "Epoch 26/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9975 - accuracy: 0.6649 - val_loss: 0.8910 - val_accuracy: 0.7010\n",
      "Epoch 27/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0092 - accuracy: 0.6612 - val_loss: 0.8802 - val_accuracy: 0.7080\n",
      "Epoch 28/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9973 - accuracy: 0.6631 - val_loss: 0.8900 - val_accuracy: 0.7034\n",
      "Epoch 29/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9903 - accuracy: 0.6669 - val_loss: 0.8418 - val_accuracy: 0.7168\n",
      "Epoch 30/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9856 - accuracy: 0.6671 - val_loss: 0.8243 - val_accuracy: 0.7176\n",
      "Epoch 31/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9801 - accuracy: 0.6698 - val_loss: 0.8605 - val_accuracy: 0.7080\n",
      "Epoch 32/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9853 - accuracy: 0.6688 - val_loss: 0.8253 - val_accuracy: 0.7232\n",
      "Epoch 33/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9797 - accuracy: 0.6702 - val_loss: 0.7681 - val_accuracy: 0.7390\n",
      "Epoch 34/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9802 - accuracy: 0.6702 - val_loss: 0.7841 - val_accuracy: 0.7334\n",
      "Epoch 35/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9639 - accuracy: 0.6724 - val_loss: 0.9060 - val_accuracy: 0.6866\n",
      "Epoch 36/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9742 - accuracy: 0.6726 - val_loss: 0.8180 - val_accuracy: 0.7332\n",
      "Epoch 37/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9589 - accuracy: 0.6776 - val_loss: 0.8572 - val_accuracy: 0.7166\n",
      "Epoch 38/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9544 - accuracy: 0.6792 - val_loss: 0.8430 - val_accuracy: 0.7224\n",
      "Epoch 39/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9541 - accuracy: 0.6816 - val_loss: 0.8050 - val_accuracy: 0.7280\n",
      "Epoch 40/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9424 - accuracy: 0.6839 - val_loss: 0.8250 - val_accuracy: 0.7264\n",
      "Epoch 41/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9498 - accuracy: 0.6815 - val_loss: 0.8616 - val_accuracy: 0.7142\n",
      "Epoch 42/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9376 - accuracy: 0.6871 - val_loss: 0.7996 - val_accuracy: 0.7296\n",
      "Epoch 43/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9355 - accuracy: 0.6868 - val_loss: 0.8071 - val_accuracy: 0.7256\n",
      "Epoch 44/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9371 - accuracy: 0.6854 - val_loss: 0.7716 - val_accuracy: 0.7336\n",
      "Epoch 45/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9383 - accuracy: 0.6844 - val_loss: 0.7137 - val_accuracy: 0.7566\n",
      "Epoch 46/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9358 - accuracy: 0.6851 - val_loss: 0.8051 - val_accuracy: 0.7400\n",
      "Epoch 47/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9324 - accuracy: 0.6881 - val_loss: 0.7793 - val_accuracy: 0.7368\n",
      "Epoch 48/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9318 - accuracy: 0.6884 - val_loss: 0.8004 - val_accuracy: 0.7324\n",
      "Epoch 49/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9336 - accuracy: 0.6879 - val_loss: 0.9259 - val_accuracy: 0.7072\n",
      "Epoch 50/50\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9289 - accuracy: 0.6854 - val_loss: 0.8624 - val_accuracy: 0.7254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f102c726f40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen, X_val, y_val, X_test, y_test = get_data_set(parameters[\"cifar10\"])\n",
    "model.fit(train_gen, \n",
    "                        epochs=50, \n",
    "                        validation_data=(X_val,y_val),\n",
    "                        batch_size=256,\n",
    "                        verbose=1,\n",
    "                    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # \"imagenet\": {\n",
    "    #     \"dataset_path\": \"Maysee/tiny-imagenet\",\n",
    "    #     \"split\": [\"train\", \"valid\"],\n",
    "    #     \"input_shape\": (64, 64, 3),\n",
    "    #     \"num_classes\": 200\n",
    "    # },\n",
    "    \"cifar10\": {\n",
    "        \"dataset_path\": \"cifar10\",\n",
    "        \"split\": [\"train\", \"test\"],\n",
    "        \"input_shape\": (32, 32, 3),\n",
    "        \"num_classes\": 10,\n",
    "        \"image_key\": \"img\",\n",
    "    },\n",
    "    # \"beans\": {\n",
    "    #     \"dataset_path\": \"beans\",\n",
    "    #     \"split\": [\"train+validation\", \"test\"],\n",
    "    #     \"input_shape\": (500, 500, 3),\n",
    "    #     \"num_classes\": 3\n",
    "    # }\n",
    "}\n",
    "\n",
    "train_gen, val_gen, X_test, y_test = get_data_set(parameters[\"cifar10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2813/2813 [==============================] - 86s 30ms/step - loss: nan - accuracy: 0.0050 - val_loss: nan - val_accuracy: 0.0050\n",
      "Epoch 2/30\n",
      "1506/2813 [===============>..............] - ETA: 34s - loss: nan - accuracy: 0.0050"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mSequential([model] \u001b[39m+\u001b[39m top_layers)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                 loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                 metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/an/Workspace/Assignment2Deeplearning/imagenet.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_gen, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mval_gen, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create model to train cifar10, resnet50\n",
    "train_gen, val_gen, X_test, y_test = get_data_set(parameters[\"imagenet\"])\n",
    "model = ResNet50(include_top=False, input_shape=parameters[\"imagenet\"][\"input_shape\"], weights=None)\n",
    "model.trainable = False\n",
    "\n",
    "top_layers = [\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = models.Sequential([model] + top_layers)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_gen, epochs=30, validation_data=val_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2813/2813 [==============================] - 131s 40ms/step - loss: 5.2076 - accuracy: 0.0214 - val_loss: 5.1881 - val_accuracy: 0.0325\n",
      "Epoch 2/10\n",
      "2813/2813 [==============================] - 112s 40ms/step - loss: 4.6504 - accuracy: 0.0601 - val_loss: 31.5217 - val_accuracy: 0.0283\n",
      "Epoch 3/10\n",
      "2813/2813 [==============================] - 114s 41ms/step - loss: 4.3422 - accuracy: 0.0968 - val_loss: 4.6474 - val_accuracy: 0.0773\n",
      "Epoch 4/10\n",
      "2813/2813 [==============================] - 112s 40ms/step - loss: 4.0425 - accuracy: 0.1353 - val_loss: 4.6451 - val_accuracy: 0.1246\n",
      "Epoch 5/10\n",
      "2813/2813 [==============================] - 112s 40ms/step - loss: 3.7925 - accuracy: 0.1714 - val_loss: 4.2395 - val_accuracy: 0.1788\n",
      "Epoch 6/10\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 3.5833 - accuracy: 0.2071 - val_loss: 6.9985 - val_accuracy: 0.1906\n",
      "Epoch 7/10\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 3.4492 - accuracy: 0.2261 - val_loss: 5.5823 - val_accuracy: 0.1917\n",
      "Epoch 8/10\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 3.3572 - accuracy: 0.2421 - val_loss: 3.5629 - val_accuracy: 0.2476\n",
      "Epoch 9/10\n",
      "2813/2813 [==============================] - 112s 40ms/step - loss: 3.2753 - accuracy: 0.2555 - val_loss: 6.1828 - val_accuracy: 0.2450\n",
      "Epoch 10/10\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 3.1531 - accuracy: 0.2780 - val_loss: 4.2581 - val_accuracy: 0.2426\n"
     ]
    }
   ],
   "source": [
    "# create model resnet to train, with top layer using batch normalization\n",
    "\n",
    "model = ResNet50(include_top=False, input_shape=(64, 64, 3), weights=None)\n",
    "\n",
    "top_flat_dense = [\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(200, activation='softmax')\n",
    "]\n",
    "\n",
    "top_global_avg_pool = [\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "    # A Convolutional Block\n",
    "top_conv_block = [\n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "model = models.Sequential([model] + top_global_avg_pool)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_gen, \n",
    "                        epochs=10, \n",
    "                        validation_data=val_gen,\n",
    "                        batch_size=32,\n",
    "                        verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, val_gen, X_test, y_test = get_data_set(parameters[\"imagenet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2813/2813 [==============================] - 134s 40ms/step - loss: 5.2146 - accuracy: 0.0263 - val_loss: 8.5242 - val_accuracy: 0.0445\n",
      "Epoch 2/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 4.6518 - accuracy: 0.0611 - val_loss: 6.0985 - val_accuracy: 0.0257\n",
      "Epoch 3/40\n",
      "2813/2813 [==============================] - 110s 39ms/step - loss: 4.1603 - accuracy: 0.1124 - val_loss: 4.3786 - val_accuracy: 0.0898\n",
      "Epoch 4/40\n",
      "2813/2813 [==============================] - 106s 38ms/step - loss: 3.8650 - accuracy: 0.1557 - val_loss: 4.3587 - val_accuracy: 0.1071\n",
      "Epoch 5/40\n",
      "2813/2813 [==============================] - 107s 38ms/step - loss: 3.6574 - accuracy: 0.1862 - val_loss: 3.6678 - val_accuracy: 0.1938\n",
      "Epoch 6/40\n",
      "2813/2813 [==============================] - 107s 38ms/step - loss: 3.4899 - accuracy: 0.2155 - val_loss: 3.6666 - val_accuracy: 0.1984\n",
      "Epoch 7/40\n",
      "2813/2813 [==============================] - 107s 38ms/step - loss: 3.3588 - accuracy: 0.2361 - val_loss: 3.4448 - val_accuracy: 0.2265\n",
      "Epoch 8/40\n",
      "2813/2813 [==============================] - 107s 38ms/step - loss: 3.2373 - accuracy: 0.2559 - val_loss: 4.2030 - val_accuracy: 0.1529\n",
      "Epoch 9/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 3.1311 - accuracy: 0.2755 - val_loss: 3.4945 - val_accuracy: 0.2260\n",
      "Epoch 10/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 3.0353 - accuracy: 0.2951 - val_loss: 3.4726 - val_accuracy: 0.2310\n",
      "Epoch 11/40\n",
      "2813/2813 [==============================] - 114s 40ms/step - loss: 2.9473 - accuracy: 0.3086 - val_loss: 3.2905 - val_accuracy: 0.2662\n",
      "Epoch 12/40\n",
      "2813/2813 [==============================] - 114s 41ms/step - loss: 2.8685 - accuracy: 0.3264 - val_loss: 3.1909 - val_accuracy: 0.2809\n",
      "Epoch 13/40\n",
      "2813/2813 [==============================] - 114s 40ms/step - loss: 2.7943 - accuracy: 0.3393 - val_loss: 3.0737 - val_accuracy: 0.2990\n",
      "Epoch 14/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 2.7315 - accuracy: 0.3505 - val_loss: 3.3464 - val_accuracy: 0.2674\n",
      "Epoch 15/40\n",
      "2813/2813 [==============================] - 114s 41ms/step - loss: 2.6603 - accuracy: 0.3632 - val_loss: 3.2714 - val_accuracy: 0.2804\n",
      "Epoch 16/40\n",
      "2813/2813 [==============================] - 114s 41ms/step - loss: 2.6039 - accuracy: 0.3744 - val_loss: 3.9180 - val_accuracy: 0.2064\n",
      "Epoch 17/40\n",
      "2813/2813 [==============================] - 115s 41ms/step - loss: 2.5472 - accuracy: 0.3853 - val_loss: 2.8591 - val_accuracy: 0.3365\n",
      "Epoch 18/40\n",
      "2813/2813 [==============================] - 115s 41ms/step - loss: 2.4892 - accuracy: 0.3979 - val_loss: 3.1092 - val_accuracy: 0.3072\n",
      "Epoch 19/40\n",
      "2813/2813 [==============================] - 114s 40ms/step - loss: 2.4252 - accuracy: 0.4111 - val_loss: 3.0909 - val_accuracy: 0.3110\n",
      "Epoch 20/40\n",
      "2813/2813 [==============================] - 114s 41ms/step - loss: 2.3689 - accuracy: 0.4222 - val_loss: 2.8654 - val_accuracy: 0.3489\n",
      "Epoch 21/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 2.3221 - accuracy: 0.4289 - val_loss: 2.9525 - val_accuracy: 0.3323\n",
      "Epoch 22/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 2.2728 - accuracy: 0.4391 - val_loss: 2.7958 - val_accuracy: 0.3563\n",
      "Epoch 23/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 2.2232 - accuracy: 0.4488 - val_loss: 2.8398 - val_accuracy: 0.3627\n",
      "Epoch 24/40\n",
      "2813/2813 [==============================] - 114s 41ms/step - loss: 2.1652 - accuracy: 0.4600 - val_loss: 2.8982 - val_accuracy: 0.3496\n",
      "Epoch 25/40\n",
      "2813/2813 [==============================] - 115s 41ms/step - loss: 2.1112 - accuracy: 0.4713 - val_loss: 2.7441 - val_accuracy: 0.3817\n",
      "Epoch 26/40\n",
      "2813/2813 [==============================] - 114s 41ms/step - loss: 2.0661 - accuracy: 0.4809 - val_loss: 3.4313 - val_accuracy: 0.2843\n",
      "Epoch 27/40\n",
      "2813/2813 [==============================] - 114s 40ms/step - loss: 2.0185 - accuracy: 0.4892 - val_loss: 2.8258 - val_accuracy: 0.3688\n",
      "Epoch 28/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 1.9688 - accuracy: 0.5002 - val_loss: 2.7027 - val_accuracy: 0.3875\n",
      "Epoch 29/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 1.9244 - accuracy: 0.5082 - val_loss: 2.7849 - val_accuracy: 0.3771\n",
      "Epoch 30/40\n",
      "2813/2813 [==============================] - 114s 40ms/step - loss: 1.8723 - accuracy: 0.5194 - val_loss: 3.1333 - val_accuracy: 0.3357\n",
      "Epoch 31/40\n",
      "2813/2813 [==============================] - 114s 41ms/step - loss: 1.8267 - accuracy: 0.5291 - val_loss: 3.5287 - val_accuracy: 0.3006\n",
      "Epoch 32/40\n",
      "2813/2813 [==============================] - 114s 41ms/step - loss: 1.7775 - accuracy: 0.5398 - val_loss: 2.7637 - val_accuracy: 0.3911\n",
      "Epoch 33/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 1.7372 - accuracy: 0.5475 - val_loss: 2.9160 - val_accuracy: 0.3702\n",
      "Epoch 34/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 1.6832 - accuracy: 0.5598 - val_loss: 2.7525 - val_accuracy: 0.3989\n",
      "Epoch 35/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 1.6405 - accuracy: 0.5691 - val_loss: 2.7348 - val_accuracy: 0.4015\n",
      "Epoch 36/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 1.5944 - accuracy: 0.5785 - val_loss: 3.0075 - val_accuracy: 0.3782\n",
      "Epoch 37/40\n",
      "2813/2813 [==============================] - 113s 40ms/step - loss: 1.5536 - accuracy: 0.5857 - val_loss: 2.9489 - val_accuracy: 0.3709\n",
      "Epoch 38/40\n",
      "2813/2813 [==============================] - 114s 40ms/step - loss: 1.5072 - accuracy: 0.5982 - val_loss: 2.7651 - val_accuracy: 0.4088\n",
      "Epoch 39/40\n",
      "2813/2813 [==============================] - 114s 41ms/step - loss: 1.4659 - accuracy: 0.6060 - val_loss: 2.8747 - val_accuracy: 0.4007\n",
      "Epoch 40/40\n",
      "2813/2813 [==============================] - 115s 41ms/step - loss: 1.4252 - accuracy: 0.6164 - val_loss: 3.0872 - val_accuracy: 0.3721\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(include_top=False, input_shape=(64, 64, 3), weights=None)\n",
    "num_classes = 200\n",
    "top_flat_dense = [\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(200, activation='softmax')\n",
    "]\n",
    "\n",
    "top_global_avg_pool = [\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "    # A Convolutional Block\n",
    "top_conv_block = [\n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        layers.Flatten(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "\n",
    "model = models.Sequential([model] + top_global_avg_pool)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_gen, \n",
    "                        epochs=40, \n",
    "                        validation_data=val_gen,\n",
    "                        batch_size=32,\n",
    "                        verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 10:10:37.521036: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 26s 7ms/step - loss: 3.3583 - accuracy: 0.2769\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.9028 - accuracy: 0.3467\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.7886 - accuracy: 0.3671\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.7019 - accuracy: 0.3802\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.6376 - accuracy: 0.3918\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.5949 - accuracy: 0.4011\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.5428 - accuracy: 0.4087\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.5260 - accuracy: 0.4128\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.4812 - accuracy: 0.4209\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.4639 - accuracy: 0.4239\n"
     ]
    }
   ],
   "source": [
    "# training EfficentNetB0 on tiny-imagenet but with freeze base model\n",
    "\n",
    "model = EfficientNetB0(include_top=False, input_shape=(64, 64, 3))\n",
    "model.trainable = False\n",
    "# Flattening and dense layers\n",
    "top_flat_dense = [\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(200, activation='softmax')\n",
    "]\n",
    "\n",
    "model = models.Sequential([model] + top_flat_dense)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
